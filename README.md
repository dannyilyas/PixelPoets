# PixelPoets

In CSC490 course, Team PixelPoets, consisting of Amane Takeuchi, Danyal Ilyas, Khanh Vo seeks to dive into the world of medical image captions. Our project embarks on a transformative journey to enhance medical image captioning, a vital component in healthcare diagnostics and education. The aim is to fine-tune the BLIP model on the MedICaT dataset, laying the groundwork for a more precise and context-aware image captioning system.

This repository contains the code, models and Final Report for PixelPoets implementaiton of "Comparing General Purpose Image Captioning Model against Fine-tuned Model for Healthcare Domain" using the fine-tuning of the pre-existing convolutional neural networks BLIP. 


The repository is strcutured as follows:

- Code: Contains all the code sectioned off into task specific scripts

- Models: Contains the zipped folder of the various fine-tuned models that were tested and evaluating during the semester

- Final Report.pdf, contains the documentation, evaluations and results in a ordered fashion

